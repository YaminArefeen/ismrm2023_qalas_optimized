{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f89384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "import math\n",
    "import torch \n",
    "import torch.autograd.forward_ad as fwad\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6bf7c",
   "metadata": {},
   "source": [
    "### defining 3D-qalas sequence parameters for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a83175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying sequence parameters\n",
    "num_reps = 5\n",
    "#-number of TR's to simulate to achieve steady state signal\n",
    "esp      = 5.74e-3 \n",
    "#-time between flip angles in the echo trains\n",
    "tf       = 128\n",
    "#-Number of echoes in each echo train (turbo factor)\n",
    "ro_gap   = 900e-3 \n",
    "#-Gap between the acquistions in each TR\n",
    "time2rel = 0\n",
    "#-Relaxation time from last acquisition to end of TR\n",
    "\n",
    "b1_val   = torch.tensor([1])\n",
    "#-B1+ for simulation\n",
    "inv_eff  = torch.tensor([1])\n",
    "#-inversion efficiency for simulation\n",
    "etl      = tf * esp\n",
    "#-length of each acquistion, given turbo factor and echo spacing\n",
    "\n",
    "#-sequence timings based on parameters defined above\n",
    "delT_M1_M2   = 109.7e-3\n",
    "delT_M0_M1   = ro_gap - etl - delT_M1_M2\n",
    "delT_M2_M3   = etl\n",
    "delT_M2_M6   = ro_gap\n",
    "delT_M4_M5   = 12.8e-3\n",
    "delT_M5_M6   = 100e-3 - 6.45e-3\n",
    "delT_M3_M4   = delT_M2_M6 - delT_M2_M3 - delT_M4_M5 - delT_M5_M6\n",
    "delT_M6_M7   = etl\n",
    "delT_M7_M8   = ro_gap - etl\n",
    "delT_M8_M9   = etl\n",
    "delT_M9_M10  = ro_gap - etl\n",
    "delT_M10_M11 = etl\n",
    "delT_M11_M12 = ro_gap - etl\n",
    "delT_M12_M13 = etl\n",
    "\n",
    "#-time between end of t2 prep pulse and first acquisition\n",
    "time_t2_prep_after = torch.tensor([9.7e-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193bf9f",
   "metadata": {},
   "source": [
    "### defining simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(alpha,parameters,num_acqs):\n",
    "\n",
    "    M0 = torch.tensor([1])\n",
    "    Mz = torch.tensor([M0])\n",
    "\n",
    "    Mxy_all = torch.zeros((num_acqs * tf,num_reps))\n",
    "\n",
    "    for reps in range(num_reps):\n",
    "        Mz = M0 - (M0 - Mz) * torch.exp(-delT_M0_M1/parameters[1])\n",
    "        Mz = Mz * (torch.sin(b1_val * torch.pi/2)**2 * torch.exp(-(delT_M1_M2-time_t2_prep_after)/parameters[0]) + \\\n",
    "                  torch.cos(b1_val * torch.pi/2)**2 * torch.exp(-(delT_M1_M2-time_t2_prep_after)/parameters[1]))\n",
    "\n",
    "        ech_ctr = 0\n",
    "        acq_ctr = 0\n",
    "        \n",
    "        #ACQ1\n",
    "        \n",
    "        if(acq_ctr < num_acqs):\n",
    "            for q in range(tf):\n",
    "                if q == 0:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-time_t2_prep_after/parameters[1])\n",
    "                else:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-esp/parameters[1])\n",
    "\n",
    "                Mxy_all[ech_ctr,reps] = torch.sin(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                Mz = torch.cos(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                ech_ctr = ech_ctr + 1\n",
    "            acq_ctr = acq_ctr + 1\n",
    "        \n",
    "        \n",
    "        if(acq_ctr < num_acqs):\n",
    "            Mz = M0 - (M0 - Mz) * torch.exp(-delT_M3_M4/parameters[1])\n",
    "            Mz = -Mz * inv_eff\n",
    "            Mz = M0 - (M0 - Mz) * torch.exp(-delT_M5_M6/parameters[1])\n",
    "\n",
    "            #ACQ2\n",
    "            for q in range(tf):\n",
    "                if q > 0:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-esp/parameters[1])\n",
    "\n",
    "                Mxy_all[ech_ctr,reps] = torch.sin(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                Mz = torch.cos(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                ech_ctr = ech_ctr + 1\n",
    "            acq_ctr = acq_ctr + 1\n",
    "\n",
    "        if(acq_ctr < num_acqs):\n",
    "            Mz = M0 - (M0 - Mz) * torch.exp(-delT_M7_M8/parameters[1])\n",
    "\n",
    "            #ACQ3\n",
    "            for q in range(tf):\n",
    "                if q > 0:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-esp/parameters[1])\n",
    "\n",
    "                Mxy_all[ech_ctr,reps] = torch.sin(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                Mz = torch.cos(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                ech_ctr = ech_ctr + 1\n",
    "            acq_ctr = acq_ctr + 1\n",
    "\n",
    "        if(acq_ctr < num_acqs):\n",
    "            Mz = M0 - (M0 - Mz) * torch.exp(-delT_M9_M10/parameters[1])\n",
    "\n",
    "            #ACQ4\n",
    "            for q in range(tf):\n",
    "                if q > 0:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-esp/parameters[1])\n",
    "\n",
    "                Mxy_all[ech_ctr,reps] = torch.sin(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                Mz = torch.cos(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                ech_ctr = ech_ctr + 1\n",
    "            acq_ctr = acq_ctr + 1\n",
    "\n",
    "        if(acq_ctr < num_acqs):\n",
    "            Mz = M0 - (M0 - Mz) * torch.exp(-delT_M11_M12/parameters[1])\n",
    "\n",
    "            #ACQ5\n",
    "            for q in range(tf):\n",
    "                if q > 0:\n",
    "                    Mz = M0 - (M0 - Mz) * torch.exp(-esp/parameters[1])\n",
    "\n",
    "                Mxy_all[ech_ctr,reps] = torch.sin(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                Mz = torch.cos(alpha[ech_ctr]) * Mz\n",
    "\n",
    "                ech_ctr = ech_ctr + 1\n",
    "    \n",
    "    return Mxy_all[:,-1] * parameters[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cffc8",
   "metadata": {},
   "source": [
    "### optimizing all flip angles in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_acqs = 3\n",
    "#-number of acquisitions we want to use\n",
    "\n",
    "#-flip angle optimization parameters\n",
    "iterations = 100\n",
    "step_size  = 1e-4\n",
    "\n",
    "#-representative tissue parameters to compute CRB for optimization\n",
    "parameters = torch.tensor([[70e-3,700e-3,1],\n",
    "                           [80e-3,1300e-3,1]])\n",
    "#                             #t2s t1 m0\n",
    "\n",
    "nparam,N = parameters.shape\n",
    "\n",
    "#-initializing flip angle train with standard 4 degree flip angles\n",
    "alpha    = torch.ones((tf*num_acqs)) * 4 / 180 * math.pi\n",
    "alpha.requires_grad = True\n",
    "\n",
    "#setting losses and tracking for optimization\n",
    "all_losses = np.zeros((iterations,1))\n",
    "alpha_init = alpha.clone()\n",
    "\n",
    "pW = torch.tensor([1,1,1])   \n",
    "#-relative weighting of each representative tissue parameter\n",
    "\n",
    "#-defining weighting matrix for each of the parameters we want to estimate\n",
    "W  = torch.zeros((N,N,nparam))\n",
    "for pp in range(nparam):\n",
    "    for nn in range(N): \n",
    "        W[nn,nn,pp] = 1 / parameters[pp,nn]**2\n",
    "        \n",
    "for ii in range(iterations):\n",
    "    total_crb = 0\n",
    "    for pp in range(nparam):\n",
    "        primal = parameters[pp,:].clone().requires_grad_()\n",
    "        tangs  = torch.eye(N)\n",
    "\n",
    "        fwd_jac = []\n",
    "\n",
    "        with fwad.dual_level():\n",
    "            #forward pass for each input\n",
    "            for tang in tangs:\n",
    "                dual_input  = fwad.make_dual(primal,tang)\n",
    "                dual_output = simulate(alpha,dual_input,num_acqs)\n",
    "\n",
    "                jacobian_column = fwad.unpack_dual(dual_output).tangent\n",
    "                fwd_jac.append(jacobian_column)\n",
    "\n",
    "        fwd_jac = torch.stack(fwd_jac).T\n",
    "        fim     = W[:,:,pp]@torch.inverse(fwd_jac.T @ fwd_jac)\n",
    "        \n",
    "        crb     = torch.real(torch.trace(fim)) * pW[pp]           \n",
    "        print('crb %d: %.2f' % (pp+1,crb))\n",
    "        total_crb = total_crb + crb\n",
    "        \n",
    "    #penalizing l2-norm of times\n",
    "    loss = total_crb\n",
    "    \n",
    "    print('iteration %d/%d || crb: %.2f || loss: %.2f' % (ii+1,iterations,total_crb,loss))\n",
    "    all_losses[ii] = loss.detach().cpu().numpy()\n",
    "\n",
    "    g_al = torch.autograd.grad(loss,alpha)[0]\n",
    "\n",
    "    alpha = alpha - step_size * g_al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5964f",
   "metadata": {},
   "source": [
    "### visualizing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef857b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam = 1\n",
    "\n",
    "alpha_orig  = torch.ones((128*5)) * 4 / 180 * math.pi\n",
    "\n",
    "init_signal = simulate(alpha_orig,parameters[nparam,:],num_acqs=5)\n",
    "sol_signal  = simulate(alpha,parameters[nparam,:],num_acqs)\n",
    "\n",
    "print('min crb: %f' % all_losses[-1])\n",
    "plt.figure\n",
    "plt.plot(all_losses.squeeze())\n",
    "plt.legend({'crb'})\n",
    "plt.show()\n",
    "\n",
    "plt.figure\n",
    "plt.plot(alpha_init.detach().numpy() / math.pi*180)\n",
    "plt.plot(alpha.detach().numpy() / math.pi*180)\n",
    "plt.show()\n",
    "\n",
    "plt.figure\n",
    "plt.plot(torch.real(init_signal.squeeze().detach()))\n",
    "plt.plot(torch.real(sol_signal.squeeze().detach()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd196a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
